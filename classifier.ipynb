{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below 2 Cells for using Image Data Generator- will take more time because it doesn't work with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir = os.path.join(os.getcwd(), \"dataset\\\\images\")\n",
    "train_dir = os.path.join(Dir, \"train\")\n",
    "validation_dir = os.path.join(Dir, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = image_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(48,48), \n",
    "                                                    batch_size=128,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    color_mode='grayscale')\n",
    "\n",
    "validation_generator = image_datagen.flow_from_directory(validation_dir,\n",
    "                                                         target_size=(48,48),\n",
    "                                                         batch_size=128,\n",
    "                                                         class_mode='categorical',\n",
    "                                                         color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below 2 cells to import data from the custom made pickle stored data- have to run \"data_generator\" file first(before running these 2 cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, validation_X, validation_y = [], [], [], []\n",
    "\n",
    "with open(\"X_train.pickle\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    \n",
    "with open(\"y_train.pickle\", \"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "    \n",
    "with open(\"X_test.pickle\", \"rb\") as f:\n",
    "    validation_X = pickle.load(f)\n",
    "    \n",
    "with open(\"y_test.pickle\", \"rb\") as f:\n",
    "    validation_y = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype=np.float32).reshape(-1, 48, 48, 1)\n",
    "validation_X = np.array(validation_X, dtype=np.float32).reshape(-1, 48, 48, 1)\n",
    "\n",
    "X /= 255\n",
    "validation_X /= 255\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y, 7)\n",
    "validation_y = tf.keras.utils.to_categorical(validation_y, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdCallBack(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if logs['val_accuracy'] >= 0.95:\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "thresholdcallback = ThresholdCallBack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               6554112   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 6,632,199\n",
      "Trainable params: 6,632,199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "def define_model():\n",
    "    model.add(Conv2D(nodes, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(2*nodes, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Conv2D(2*2*nodes, kernel_size=(3,3), activation='relu'))\n",
    "#     model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(8*nodes, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.4763 - accuracy: 0.4316 - val_loss: 1.3828 - val_accuracy: 0.4758\n",
      "Epoch 2/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.3921 - accuracy: 0.4631 - val_loss: 1.3202 - val_accuracy: 0.4918\n",
      "Epoch 3/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.3248 - accuracy: 0.4912 - val_loss: 1.2858 - val_accuracy: 0.5132\n",
      "Epoch 4/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.2675 - accuracy: 0.5163 - val_loss: 1.2641 - val_accuracy: 0.5225\n",
      "Epoch 5/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.2113 - accuracy: 0.5406 - val_loss: 1.2307 - val_accuracy: 0.5368\n",
      "Epoch 6/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 1.1692 - accuracy: 0.5548 - val_loss: 1.2358 - val_accuracy: 0.5405\n",
      "Epoch 7/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.1206 - accuracy: 0.5769 - val_loss: 1.2001 - val_accuracy: 0.5515\n",
      "Epoch 8/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.0763 - accuracy: 0.5905 - val_loss: 1.2015 - val_accuracy: 0.5497\n",
      "Epoch 9/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.0406 - accuracy: 0.6083 - val_loss: 1.1743 - val_accuracy: 0.5668\n",
      "Epoch 10/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 1.0011 - accuracy: 0.6236 - val_loss: 1.1818 - val_accuracy: 0.5610\n",
      "Epoch 11/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.9730 - accuracy: 0.6380 - val_loss: 1.1974 - val_accuracy: 0.5616\n",
      "Epoch 12/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.9372 - accuracy: 0.6468 - val_loss: 1.2011 - val_accuracy: 0.5568\n",
      "Epoch 13/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.9044 - accuracy: 0.6607 - val_loss: 1.2126 - val_accuracy: 0.5674\n",
      "Epoch 14/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.8838 - accuracy: 0.6691 - val_loss: 1.2009 - val_accuracy: 0.5668\n",
      "Epoch 15/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.8586 - accuracy: 0.6781 - val_loss: 1.2054 - val_accuracy: 0.5659\n",
      "Epoch 16/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.8302 - accuracy: 0.6921 - val_loss: 1.2127 - val_accuracy: 0.5722\n",
      "Epoch 17/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.8028 - accuracy: 0.7018 - val_loss: 1.2382 - val_accuracy: 0.5708\n",
      "Epoch 18/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.7834 - accuracy: 0.7073 - val_loss: 1.2169 - val_accuracy: 0.5674\n",
      "Epoch 19/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.7562 - accuracy: 0.7180 - val_loss: 1.2300 - val_accuracy: 0.5655\n",
      "Epoch 20/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.7437 - accuracy: 0.7205 - val_loss: 1.2505 - val_accuracy: 0.5651\n",
      "Epoch 21/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.7279 - accuracy: 0.7319 - val_loss: 1.2512 - val_accuracy: 0.5698\n",
      "Epoch 22/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.7039 - accuracy: 0.7395 - val_loss: 1.2637 - val_accuracy: 0.5682\n",
      "Epoch 23/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.6927 - accuracy: 0.7424 - val_loss: 1.2860 - val_accuracy: 0.5737\n",
      "Epoch 24/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.6726 - accuracy: 0.7533 - val_loss: 1.2912 - val_accuracy: 0.5668\n",
      "Epoch 25/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.6587 - accuracy: 0.7580 - val_loss: 1.2936 - val_accuracy: 0.5675\n",
      "Epoch 26/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.6437 - accuracy: 0.7619 - val_loss: 1.3092 - val_accuracy: 0.5698\n",
      "Epoch 27/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.6303 - accuracy: 0.7683 - val_loss: 1.3430 - val_accuracy: 0.5691\n",
      "Epoch 28/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.6230 - accuracy: 0.7701 - val_loss: 1.3280 - val_accuracy: 0.5664\n",
      "Epoch 29/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.6063 - accuracy: 0.7792 - val_loss: 1.3252 - val_accuracy: 0.5665\n",
      "Epoch 30/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5928 - accuracy: 0.7845 - val_loss: 1.3438 - val_accuracy: 0.5757\n",
      "Epoch 31/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5912 - accuracy: 0.7818 - val_loss: 1.3403 - val_accuracy: 0.5662\n",
      "Epoch 32/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5772 - accuracy: 0.7897 - val_loss: 1.3850 - val_accuracy: 0.5726\n",
      "Epoch 33/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5634 - accuracy: 0.7932 - val_loss: 1.3514 - val_accuracy: 0.5804\n",
      "Epoch 34/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5434 - accuracy: 0.8010 - val_loss: 1.3510 - val_accuracy: 0.5671\n",
      "Epoch 35/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5361 - accuracy: 0.8059 - val_loss: 1.3495 - val_accuracy: 0.5763\n",
      "Epoch 36/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5346 - accuracy: 0.8052 - val_loss: 1.4078 - val_accuracy: 0.5740\n",
      "Epoch 37/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.5224 - accuracy: 0.8095 - val_loss: 1.4064 - val_accuracy: 0.5713\n",
      "Epoch 38/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5130 - accuracy: 0.8139 - val_loss: 1.4451 - val_accuracy: 0.5654\n",
      "Epoch 39/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.5011 - accuracy: 0.8201 - val_loss: 1.3880 - val_accuracy: 0.5732\n",
      "Epoch 40/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4980 - accuracy: 0.8216 - val_loss: 1.4166 - val_accuracy: 0.5662\n",
      "Epoch 41/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4832 - accuracy: 0.8270 - val_loss: 1.4333 - val_accuracy: 0.5668\n",
      "Epoch 42/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4767 - accuracy: 0.8286 - val_loss: 1.4155 - val_accuracy: 0.5710\n",
      "Epoch 43/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4796 - accuracy: 0.8262 - val_loss: 1.4617 - val_accuracy: 0.5702\n",
      "Epoch 44/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4656 - accuracy: 0.8329 - val_loss: 1.4225 - val_accuracy: 0.5763\n",
      "Epoch 45/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4614 - accuracy: 0.8346 - val_loss: 1.4289 - val_accuracy: 0.5722\n",
      "Epoch 46/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4582 - accuracy: 0.8350 - val_loss: 1.4659 - val_accuracy: 0.5732\n",
      "Epoch 47/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4544 - accuracy: 0.8379 - val_loss: 1.4613 - val_accuracy: 0.5743\n",
      "Epoch 48/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4376 - accuracy: 0.8430 - val_loss: 1.4706 - val_accuracy: 0.5733\n",
      "Epoch 49/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.4431 - accuracy: 0.8405 - val_loss: 1.4707 - val_accuracy: 0.5659\n",
      "Epoch 50/300\n",
      "901/901 [==============================] - 16s 18ms/step - loss: 0.4302 - accuracy: 0.8446 - val_loss: 1.4599 - val_accuracy: 0.5743\n",
      "Epoch 51/300\n",
      "901/901 [==============================] - 16s 18ms/step - loss: 0.4237 - accuracy: 0.8476 - val_loss: 1.5253 - val_accuracy: 0.5726\n",
      "Epoch 52/300\n",
      "901/901 [==============================] - 16s 18ms/step - loss: 0.4130 - accuracy: 0.8534 - val_loss: 1.5455 - val_accuracy: 0.5737\n",
      "Epoch 53/300\n",
      "901/901 [==============================] - 16s 18ms/step - loss: 0.4189 - accuracy: 0.8524 - val_loss: 1.4939 - val_accuracy: 0.5676\n",
      "Epoch 54/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.4125 - accuracy: 0.8548 - val_loss: 1.4919 - val_accuracy: 0.5627\n",
      "Epoch 55/300\n",
      "901/901 [==============================] - 17s 18ms/step - loss: 0.4034 - accuracy: 0.8565 - val_loss: 1.5486 - val_accuracy: 0.5729\n",
      "Epoch 56/300\n",
      "901/901 [==============================] - 17s 19ms/step - loss: 0.3967 - accuracy: 0.8587 - val_loss: 1.5208 - val_accuracy: 0.5719\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 17s 19ms/step - loss: 0.3995 - accuracy: 0.8593 - val_loss: 1.5551 - val_accuracy: 0.5719\n",
      "Epoch 58/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3931 - accuracy: 0.8603 - val_loss: 1.5451 - val_accuracy: 0.5696\n",
      "Epoch 59/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.3856 - accuracy: 0.8641 - val_loss: 1.5066 - val_accuracy: 0.5703\n",
      "Epoch 60/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3726 - accuracy: 0.8702 - val_loss: 1.5443 - val_accuracy: 0.5774\n",
      "Epoch 61/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3708 - accuracy: 0.8694 - val_loss: 1.5038 - val_accuracy: 0.5736\n",
      "Epoch 62/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3695 - accuracy: 0.8711 - val_loss: 1.6102 - val_accuracy: 0.5682\n",
      "Epoch 63/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.3717 - accuracy: 0.8674 - val_loss: 1.5766 - val_accuracy: 0.5637\n",
      "Epoch 64/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.3600 - accuracy: 0.8736 - val_loss: 1.5742 - val_accuracy: 0.5733\n",
      "Epoch 65/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.3678 - accuracy: 0.8718 - val_loss: 1.5696 - val_accuracy: 0.5699\n",
      "Epoch 66/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3609 - accuracy: 0.8729 - val_loss: 1.5580 - val_accuracy: 0.5719\n",
      "Epoch 67/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3552 - accuracy: 0.8755 - val_loss: 1.5866 - val_accuracy: 0.5678\n",
      "Epoch 68/300\n",
      "901/901 [==============================] - 16s 18ms/step - loss: 0.3519 - accuracy: 0.8780 - val_loss: 1.5945 - val_accuracy: 0.5706\n",
      "Epoch 69/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3519 - accuracy: 0.8762 - val_loss: 1.5492 - val_accuracy: 0.5705\n",
      "Epoch 70/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3423 - accuracy: 0.8806 - val_loss: 1.6186 - val_accuracy: 0.5716\n",
      "Epoch 71/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3519 - accuracy: 0.8758 - val_loss: 1.6029 - val_accuracy: 0.5773\n",
      "Epoch 72/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3444 - accuracy: 0.8795 - val_loss: 1.6166 - val_accuracy: 0.5740\n",
      "Epoch 73/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3365 - accuracy: 0.8812 - val_loss: 1.5682 - val_accuracy: 0.5693\n",
      "Epoch 74/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.3295 - accuracy: 0.8842 - val_loss: 1.6118 - val_accuracy: 0.5757\n",
      "Epoch 75/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3354 - accuracy: 0.8843 - val_loss: 1.5680 - val_accuracy: 0.5703\n",
      "Epoch 76/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3271 - accuracy: 0.8856 - val_loss: 1.6180 - val_accuracy: 0.5703\n",
      "Epoch 77/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3291 - accuracy: 0.8863 - val_loss: 1.5670 - val_accuracy: 0.5669\n",
      "Epoch 78/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3246 - accuracy: 0.8854 - val_loss: 1.5954 - val_accuracy: 0.5706\n",
      "Epoch 79/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3198 - accuracy: 0.8894 - val_loss: 1.6282 - val_accuracy: 0.5749\n",
      "Epoch 80/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3159 - accuracy: 0.8903 - val_loss: 1.6044 - val_accuracy: 0.5715\n",
      "Epoch 81/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.3099 - accuracy: 0.8937 - val_loss: 1.6881 - val_accuracy: 0.5701\n",
      "Epoch 82/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3224 - accuracy: 0.8902 - val_loss: 1.6164 - val_accuracy: 0.5761\n",
      "Epoch 83/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3129 - accuracy: 0.8930 - val_loss: 1.6176 - val_accuracy: 0.5720\n",
      "Epoch 84/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.3100 - accuracy: 0.8945 - val_loss: 1.6300 - val_accuracy: 0.5739\n",
      "Epoch 85/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3112 - accuracy: 0.8918 - val_loss: 1.6291 - val_accuracy: 0.5781\n",
      "Epoch 86/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3014 - accuracy: 0.8941 - val_loss: 1.6380 - val_accuracy: 0.5749\n",
      "Epoch 87/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2981 - accuracy: 0.8950 - val_loss: 1.6344 - val_accuracy: 0.5780\n",
      "Epoch 88/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2973 - accuracy: 0.8968 - val_loss: 1.6652 - val_accuracy: 0.5716\n",
      "Epoch 89/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2956 - accuracy: 0.8976 - val_loss: 1.6921 - val_accuracy: 0.5678\n",
      "Epoch 90/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.3031 - accuracy: 0.8947 - val_loss: 1.6480 - val_accuracy: 0.5736\n",
      "Epoch 91/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2919 - accuracy: 0.8982 - val_loss: 1.6658 - val_accuracy: 0.5785\n",
      "Epoch 92/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2956 - accuracy: 0.8982 - val_loss: 1.6897 - val_accuracy: 0.5737\n",
      "Epoch 93/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2932 - accuracy: 0.8974 - val_loss: 1.6034 - val_accuracy: 0.5691\n",
      "Epoch 94/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2892 - accuracy: 0.9001 - val_loss: 1.6994 - val_accuracy: 0.5713\n",
      "Epoch 95/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.2863 - accuracy: 0.9024 - val_loss: 1.6643 - val_accuracy: 0.5702\n",
      "Epoch 96/300\n",
      "901/901 [==============================] - 16s 18ms/step - loss: 0.2892 - accuracy: 0.9010 - val_loss: 1.6728 - val_accuracy: 0.5716\n",
      "Epoch 97/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.2745 - accuracy: 0.9049 - val_loss: 1.7010 - val_accuracy: 0.5753\n",
      "Epoch 98/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2834 - accuracy: 0.9026 - val_loss: 1.7040 - val_accuracy: 0.5764\n",
      "Epoch 99/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2778 - accuracy: 0.9055 - val_loss: 1.7273 - val_accuracy: 0.5702\n",
      "Epoch 100/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2808 - accuracy: 0.9048 - val_loss: 1.7180 - val_accuracy: 0.5740\n",
      "Epoch 101/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2815 - accuracy: 0.9034 - val_loss: 1.7542 - val_accuracy: 0.5794\n",
      "Epoch 102/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2688 - accuracy: 0.9092 - val_loss: 1.6853 - val_accuracy: 0.5720\n",
      "Epoch 103/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2768 - accuracy: 0.9074 - val_loss: 1.6772 - val_accuracy: 0.5699\n",
      "Epoch 104/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2737 - accuracy: 0.9068 - val_loss: 1.6913 - val_accuracy: 0.5720\n",
      "Epoch 105/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.2702 - accuracy: 0.9059 - val_loss: 1.6961 - val_accuracy: 0.5716\n",
      "Epoch 106/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2785 - accuracy: 0.9039 - val_loss: 1.7394 - val_accuracy: 0.5737\n",
      "Epoch 107/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2675 - accuracy: 0.9096 - val_loss: 1.7569 - val_accuracy: 0.5749\n",
      "Epoch 108/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2710 - accuracy: 0.9073 - val_loss: 1.7148 - val_accuracy: 0.5685\n",
      "Epoch 109/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2574 - accuracy: 0.9126 - val_loss: 1.7670 - val_accuracy: 0.5784\n",
      "Epoch 110/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2643 - accuracy: 0.9108 - val_loss: 1.7565 - val_accuracy: 0.5780\n",
      "Epoch 111/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2532 - accuracy: 0.9134 - val_loss: 1.7248 - val_accuracy: 0.5763\n",
      "Epoch 112/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2609 - accuracy: 0.9120 - val_loss: 1.6897 - val_accuracy: 0.5768\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2667 - accuracy: 0.9093 - val_loss: 1.7208 - val_accuracy: 0.5730\n",
      "Epoch 114/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2540 - accuracy: 0.9112 - val_loss: 1.7352 - val_accuracy: 0.5783\n",
      "Epoch 115/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2551 - accuracy: 0.9129 - val_loss: 1.8332 - val_accuracy: 0.5784\n",
      "Epoch 116/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2524 - accuracy: 0.9139 - val_loss: 1.7629 - val_accuracy: 0.5720\n",
      "Epoch 117/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2630 - accuracy: 0.9117 - val_loss: 1.7860 - val_accuracy: 0.5736\n",
      "Epoch 118/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2493 - accuracy: 0.9154 - val_loss: 1.8084 - val_accuracy: 0.5716\n",
      "Epoch 119/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2423 - accuracy: 0.9158 - val_loss: 1.7774 - val_accuracy: 0.5720\n",
      "Epoch 120/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2528 - accuracy: 0.9120 - val_loss: 1.7574 - val_accuracy: 0.5692\n",
      "Epoch 121/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2580 - accuracy: 0.9132 - val_loss: 1.7370 - val_accuracy: 0.5705\n",
      "Epoch 122/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2557 - accuracy: 0.9146 - val_loss: 1.7444 - val_accuracy: 0.5716\n",
      "Epoch 123/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2466 - accuracy: 0.9171 - val_loss: 1.7754 - val_accuracy: 0.5672\n",
      "Epoch 124/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2427 - accuracy: 0.9202 - val_loss: 1.8042 - val_accuracy: 0.5668\n",
      "Epoch 125/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2485 - accuracy: 0.9156 - val_loss: 1.7447 - val_accuracy: 0.5620\n",
      "Epoch 126/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2408 - accuracy: 0.9184 - val_loss: 1.7865 - val_accuracy: 0.5675\n",
      "Epoch 127/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2396 - accuracy: 0.9181 - val_loss: 1.7893 - val_accuracy: 0.5701\n",
      "Epoch 128/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2449 - accuracy: 0.9164 - val_loss: 1.7436 - val_accuracy: 0.5692\n",
      "Epoch 129/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2440 - accuracy: 0.9170 - val_loss: 1.7321 - val_accuracy: 0.5685\n",
      "Epoch 130/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2380 - accuracy: 0.9209 - val_loss: 1.8195 - val_accuracy: 0.5701\n",
      "Epoch 131/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2375 - accuracy: 0.9208 - val_loss: 1.7451 - val_accuracy: 0.5655\n",
      "Epoch 132/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2372 - accuracy: 0.9211 - val_loss: 1.7817 - val_accuracy: 0.5672\n",
      "Epoch 133/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2427 - accuracy: 0.9179 - val_loss: 1.8271 - val_accuracy: 0.5669\n",
      "Epoch 134/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2401 - accuracy: 0.9181 - val_loss: 1.7652 - val_accuracy: 0.5722\n",
      "Epoch 135/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2351 - accuracy: 0.9215 - val_loss: 1.8679 - val_accuracy: 0.5662\n",
      "Epoch 136/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2318 - accuracy: 0.9203 - val_loss: 1.7536 - val_accuracy: 0.5665\n",
      "Epoch 137/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2353 - accuracy: 0.9191 - val_loss: 1.7928 - val_accuracy: 0.5718\n",
      "Epoch 138/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2326 - accuracy: 0.9211 - val_loss: 1.7466 - val_accuracy: 0.5693\n",
      "Epoch 139/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2364 - accuracy: 0.9214 - val_loss: 1.8086 - val_accuracy: 0.5727\n",
      "Epoch 140/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2336 - accuracy: 0.9205 - val_loss: 1.7693 - val_accuracy: 0.5631\n",
      "Epoch 141/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2294 - accuracy: 0.9235 - val_loss: 1.7581 - val_accuracy: 0.5671oss: 0.228\n",
      "Epoch 142/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2288 - accuracy: 0.9240 - val_loss: 1.8370 - val_accuracy: 0.5747\n",
      "Epoch 143/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2168 - accuracy: 0.9252 - val_loss: 1.7881 - val_accuracy: 0.5679\n",
      "Epoch 144/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2425 - accuracy: 0.9204 - val_loss: 1.8266 - val_accuracy: 0.5659\n",
      "Epoch 145/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2306 - accuracy: 0.9223 - val_loss: 1.8361 - val_accuracy: 0.5669\n",
      "Epoch 146/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2304 - accuracy: 0.9241 - val_loss: 1.8074 - val_accuracy: 0.5662\n",
      "Epoch 147/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2269 - accuracy: 0.9241 - val_loss: 1.8741 - val_accuracy: 0.5655\n",
      "Epoch 148/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2215 - accuracy: 0.9234 - val_loss: 1.8859 - val_accuracy: 0.5655\n",
      "Epoch 149/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2157 - accuracy: 0.9298 - val_loss: 1.9546 - val_accuracy: 0.5716 loss: 0.2168 \n",
      "Epoch 150/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2231 - accuracy: 0.9233 - val_loss: 1.7998 - val_accuracy: 0.5650\n",
      "Epoch 151/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2211 - accuracy: 0.9254 - val_loss: 1.7992 - val_accuracy: 0.5720\n",
      "Epoch 152/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2228 - accuracy: 0.9249 - val_loss: 1.8767 - val_accuracy: 0.5643\n",
      "Epoch 153/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2322 - accuracy: 0.9238 - val_loss: 1.7962 - val_accuracy: 0.5698\n",
      "Epoch 154/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2267 - accuracy: 0.9242 - val_loss: 1.7577 - val_accuracy: 0.5710\n",
      "Epoch 155/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2260 - accuracy: 0.9242 - val_loss: 1.7968 - val_accuracy: 0.5692\n",
      "Epoch 156/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2220 - accuracy: 0.9264 - val_loss: 1.8142 - val_accuracy: 0.5684\n",
      "Epoch 157/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2287 - accuracy: 0.9213 - val_loss: 1.8086 - val_accuracy: 0.5688\n",
      "Epoch 158/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2122 - accuracy: 0.9278 - val_loss: 1.8211 - val_accuracy: 0.5671\n",
      "Epoch 159/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2199 - accuracy: 0.9255 - val_loss: 1.8453 - val_accuracy: 0.5749\n",
      "Epoch 160/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2098 - accuracy: 0.9302 - val_loss: 1.8151 - val_accuracy: 0.5679\n",
      "Epoch 161/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2190 - accuracy: 0.9264 - val_loss: 1.8782 - val_accuracy: 0.5691\n",
      "Epoch 162/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2178 - accuracy: 0.9262 - val_loss: 1.7743 - val_accuracy: 0.5739\n",
      "Epoch 163/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2158 - accuracy: 0.9282 - val_loss: 1.8917 - val_accuracy: 0.5692\n",
      "Epoch 164/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2210 - accuracy: 0.9257 - val_loss: 1.9372 - val_accuracy: 0.5658\n",
      "Epoch 165/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.2083 - accuracy: 0.9302 - val_loss: 1.8986 - val_accuracy: 0.5665\n",
      "Epoch 166/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2167 - accuracy: 0.9271 - val_loss: 1.8596 - val_accuracy: 0.5654\n",
      "Epoch 167/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2141 - accuracy: 0.9277 - val_loss: 1.8812 - val_accuracy: 0.5671\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2070 - accuracy: 0.9314 - val_loss: 1.8604 - val_accuracy: 0.5667\n",
      "Epoch 169/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2167 - accuracy: 0.9265 - val_loss: 1.7880 - val_accuracy: 0.5626s: 0\n",
      "Epoch 170/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2068 - accuracy: 0.9315 - val_loss: 1.9009 - val_accuracy: 0.5705\n",
      "Epoch 171/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2128 - accuracy: 0.9293 - val_loss: 1.8549 - val_accuracy: 0.5699\n",
      "Epoch 172/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2030 - accuracy: 0.9314 - val_loss: 1.9131 - val_accuracy: 0.5723\n",
      "Epoch 173/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2025 - accuracy: 0.9318 - val_loss: 1.8746 - val_accuracy: 0.5698\n",
      "Epoch 174/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2065 - accuracy: 0.9314 - val_loss: 1.8756 - val_accuracy: 0.5725\n",
      "Epoch 175/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2102 - accuracy: 0.9304 - val_loss: 1.8347 - val_accuracy: 0.5710\n",
      "Epoch 176/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2099 - accuracy: 0.9301 - val_loss: 1.7953 - val_accuracy: 0.5719\n",
      "Epoch 177/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2047 - accuracy: 0.9316 - val_loss: 1.8733 - val_accuracy: 0.56130s - loss: 0.2042 - accuracy: 0.\n",
      "Epoch 178/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2107 - accuracy: 0.9294 - val_loss: 1.8984 - val_accuracy: 0.5678\n",
      "Epoch 179/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2008 - accuracy: 0.9327 - val_loss: 1.9232 - val_accuracy: 0.5650\n",
      "Epoch 180/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2087 - accuracy: 0.9306 - val_loss: 1.8970 - val_accuracy: 0.5740\n",
      "Epoch 181/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2010 - accuracy: 0.9353 - val_loss: 1.8571 - val_accuracy: 0.5699\n",
      "Epoch 182/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2044 - accuracy: 0.9312 - val_loss: 1.9338 - val_accuracy: 0.5699\n",
      "Epoch 183/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2068 - accuracy: 0.9303 - val_loss: 1.8789 - val_accuracy: 0.5725\n",
      "Epoch 184/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1961 - accuracy: 0.9354 - val_loss: 1.9218 - val_accuracy: 0.5702\n",
      "Epoch 185/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2066 - accuracy: 0.9320 - val_loss: 1.9103 - val_accuracy: 0.5723\n",
      "Epoch 186/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2091 - accuracy: 0.9291 - val_loss: 1.8650 - val_accuracy: 0.5665\n",
      "Epoch 187/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2056 - accuracy: 0.9326 - val_loss: 1.9050 - val_accuracy: 0.5686\n",
      "Epoch 188/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2088 - accuracy: 0.9310 - val_loss: 1.8957 - val_accuracy: 0.5676\n",
      "Epoch 189/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2043 - accuracy: 0.9323 - val_loss: 1.9125 - val_accuracy: 0.5681\n",
      "Epoch 190/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1983 - accuracy: 0.9340 - val_loss: 1.9865 - val_accuracy: 0.5686\n",
      "Epoch 191/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2049 - accuracy: 0.9336 - val_loss: 1.8513 - val_accuracy: 0.5703\n",
      "Epoch 192/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2003 - accuracy: 0.9348 - val_loss: 1.9001 - val_accuracy: 0.5682\n",
      "Epoch 193/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1953 - accuracy: 0.9366 - val_loss: 1.9070 - val_accuracy: 0.5669\n",
      "Epoch 194/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2037 - accuracy: 0.9328 - val_loss: 1.9414 - val_accuracy: 0.5735\n",
      "Epoch 195/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1991 - accuracy: 0.9346 - val_loss: 1.8728 - val_accuracy: 0.5674\n",
      "Epoch 196/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1997 - accuracy: 0.9357 - val_loss: 1.8733 - val_accuracy: 0.5705\n",
      "Epoch 197/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1922 - accuracy: 0.9362 - val_loss: 2.0362 - val_accuracy: 0.5729\n",
      "Epoch 198/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1910 - accuracy: 0.9363 - val_loss: 1.9257 - val_accuracy: 0.5676\n",
      "Epoch 199/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2016 - accuracy: 0.9334 - val_loss: 1.8424 - val_accuracy: 0.5679\n",
      "Epoch 200/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.2017 - accuracy: 0.9327 - val_loss: 1.9632 - val_accuracy: 0.5658curacy - ETA - ETA: 3s - loss: 0.2040 - accuracy - ETA: 3s - loss:\n",
      "Epoch 201/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1925 - accuracy: 0.9357 - val_loss: 1.9111 - val_accuracy: 0.5652\n",
      "Epoch 202/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1959 - accuracy: 0.9358 - val_loss: 1.9801 - val_accuracy: 0.5736\n",
      "Epoch 203/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1943 - accuracy: 0.9344 - val_loss: 1.9830 - val_accuracy: 0.5664\n",
      "Epoch 204/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1891 - accuracy: 0.9356 - val_loss: 2.0157 - val_accuracy: 0.5723\n",
      "Epoch 205/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1974 - accuracy: 0.9357 - val_loss: 1.9353 - val_accuracy: 0.5634\n",
      "Epoch 206/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1911 - accuracy: 0.9364 - val_loss: 1.9049 - val_accuracy: 0.5701\n",
      "Epoch 207/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1895 - accuracy: 0.9384 - val_loss: 1.9466 - val_accuracy: 0.5674\n",
      "Epoch 208/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1883 - accuracy: 0.9376 - val_loss: 1.9461 - val_accuracy: 0.5718\n",
      "Epoch 209/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1959 - accuracy: 0.9363 - val_loss: 1.8538 - val_accuracy: 0.5645\n",
      "Epoch 210/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1927 - accuracy: 0.9366 - val_loss: 1.9823 - val_accuracy: 0.5696\n",
      "Epoch 211/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1998 - accuracy: 0.9345 - val_loss: 1.8882 - val_accuracy: 0.5675\n",
      "Epoch 212/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1878 - accuracy: 0.9384 - val_loss: 2.0327 - val_accuracy: 0.5708\n",
      "Epoch 213/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1937 - accuracy: 0.9354 - val_loss: 1.9554 - val_accuracy: 0.5681\n",
      "Epoch 214/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1913 - accuracy: 0.9383 - val_loss: 2.0336 - val_accuracy: 0.5678\n",
      "Epoch 215/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1917 - accuracy: 0.9380 - val_loss: 1.9577 - val_accuracy: 0.5705\n",
      "Epoch 216/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1854 - accuracy: 0.9382 - val_loss: 1.9148 - val_accuracy: 0.5672\n",
      "Epoch 217/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1929 - accuracy: 0.9349 - val_loss: 1.9205 - val_accuracy: 0.5640\n",
      "Epoch 218/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1874 - accuracy: 0.9378 - val_loss: 2.0502 - val_accuracy: 0.5675\n",
      "Epoch 219/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1973 - accuracy: 0.9352 - val_loss: 2.0299 - val_accuracy: 0.5648\n",
      "Epoch 220/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1914 - accuracy: 0.9376 - val_loss: 1.9432 - val_accuracy: 0.5706\n",
      "Epoch 221/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1946 - accuracy: 0.9345 - val_loss: 1.9095 - val_accuracy: 0.5644\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1887 - accuracy: 0.9386 - val_loss: 1.9471 - val_accuracy: 0.5698\n",
      "Epoch 223/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1933 - accuracy: 0.9378 - val_loss: 2.0372 - val_accuracy: 0.5701\n",
      "Epoch 224/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1896 - accuracy: 0.9391 - val_loss: 1.9122 - val_accuracy: 0.5705\n",
      "Epoch 225/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1888 - accuracy: 0.9375 - val_loss: 1.9399 - val_accuracy: 0.5658\n",
      "Epoch 226/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1786 - accuracy: 0.9409 - val_loss: 1.9247 - val_accuracy: 0.5620\n",
      "Epoch 227/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1801 - accuracy: 0.9408 - val_loss: 1.9894 - val_accuracy: 0.5641\n",
      "Epoch 228/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1912 - accuracy: 0.9380 - val_loss: 1.9551 - val_accuracy: 0.5747\n",
      "Epoch 229/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1821 - accuracy: 0.9398 - val_loss: 1.9511 - val_accuracy: 0.5650\n",
      "Epoch 230/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1852 - accuracy: 0.9399 - val_loss: 1.9601 - val_accuracy: 0.5689s:\n",
      "Epoch 231/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1872 - accuracy: 0.9390 - val_loss: 1.9410 - val_accuracy: 0.5645\n",
      "Epoch 232/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1828 - accuracy: 0.9401 - val_loss: 2.0552 - val_accuracy: 0.5682\n",
      "Epoch 233/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1840 - accuracy: 0.9404 - val_loss: 2.0558 - val_accuracy: 0.5757\n",
      "Epoch 234/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1904 - accuracy: 0.9371 - val_loss: 2.0012 - val_accuracy: 0.5659\n",
      "Epoch 235/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1718 - accuracy: 0.9433 - val_loss: 1.9697 - val_accuracy: 0.5611\n",
      "Epoch 236/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1898 - accuracy: 0.9369 - val_loss: 1.9677 - val_accuracy: 0.5668\n",
      "Epoch 237/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1711 - accuracy: 0.9446 - val_loss: 2.0251 - val_accuracy: 0.5637\n",
      "Epoch 238/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1880 - accuracy: 0.9389 - val_loss: 1.8966 - val_accuracy: 0.5592\n",
      "Epoch 239/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1857 - accuracy: 0.9393 - val_loss: 1.9064 - val_accuracy: 0.5624\n",
      "Epoch 240/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1886 - accuracy: 0.9379 - val_loss: 1.9242 - val_accuracy: 0.5664\n",
      "Epoch 241/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1839 - accuracy: 0.9397 - val_loss: 2.0026 - val_accuracy: 0.5638\n",
      "Epoch 242/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1803 - accuracy: 0.9418 - val_loss: 1.9711 - val_accuracy: 0.5643\n",
      "Epoch 243/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.1824 - accuracy: 0.9398 - val_loss: 1.9415 - val_accuracy: 0.5713\n",
      "Epoch 244/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1850 - accuracy: 0.9392 - val_loss: 2.0321 - val_accuracy: 0.5607\n",
      "Epoch 245/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1857 - accuracy: 0.9406 - val_loss: 1.9212 - val_accuracy: 0.5648\n",
      "Epoch 246/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1811 - accuracy: 0.9412 - val_loss: 2.0274 - val_accuracy: 0.5618\n",
      "Epoch 247/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1855 - accuracy: 0.9396 - val_loss: 1.9091 - val_accuracy: 0.5624\n",
      "Epoch 248/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1733 - accuracy: 0.9417 - val_loss: 2.0179 - val_accuracy: 0.5672\n",
      "Epoch 249/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1826 - accuracy: 0.9406 - val_loss: 2.0897 - val_accuracy: 0.5627\n",
      "Epoch 250/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1876 - accuracy: 0.9384 - val_loss: 1.9530 - val_accuracy: 0.5692\n",
      "Epoch 251/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1787 - accuracy: 0.9395 - val_loss: 2.0031 - val_accuracy: 0.5691\n",
      "Epoch 252/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1804 - accuracy: 0.9409 - val_loss: 1.9071 - val_accuracy: 0.5633: 4s - loss: 0.1720 - accuracy - ETA: 4s - loss: 0.1723 - \n",
      "Epoch 253/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1784 - accuracy: 0.9415 - val_loss: 1.9786 - val_accuracy: 0.5674\n",
      "Epoch 254/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1840 - accuracy: 0.9392 - val_loss: 1.9779 - val_accuracy: 0.5655\n",
      "Epoch 255/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1734 - accuracy: 0.9435 - val_loss: 1.9880 - val_accuracy: 0.5695\n",
      "Epoch 256/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1765 - accuracy: 0.9412 - val_loss: 1.9867 - val_accuracy: 0.5635\n",
      "Epoch 257/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1748 - accuracy: 0.9432 - val_loss: 2.0232 - val_accuracy: 0.5645\n",
      "Epoch 258/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1814 - accuracy: 0.9421 - val_loss: 2.0325 - val_accuracy: 0.5626\n",
      "Epoch 259/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1811 - accuracy: 0.9409 - val_loss: 1.9865 - val_accuracy: 0.5650\n",
      "Epoch 260/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1867 - accuracy: 0.9388 - val_loss: 1.9761 - val_accuracy: 0.5655\n",
      "Epoch 261/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1696 - accuracy: 0.9446 - val_loss: 2.0133 - val_accuracy: 0.5647\n",
      "Epoch 262/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1752 - accuracy: 0.9431 - val_loss: 2.0992 - val_accuracy: 0.5654\n",
      "Epoch 263/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1790 - accuracy: 0.9424 - val_loss: 1.9257 - val_accuracy: 0.5637\n",
      "Epoch 264/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1752 - accuracy: 0.9431 - val_loss: 1.9273 - val_accuracy: 0.5686\n",
      "Epoch 265/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1721 - accuracy: 0.9445 - val_loss: 1.9848 - val_accuracy: 0.5676\n",
      "Epoch 266/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1747 - accuracy: 0.9433 - val_loss: 2.0578 - val_accuracy: 0.5618\n",
      "Epoch 267/300\n",
      "901/901 [==============================] - 16s 17ms/step - loss: 0.1729 - accuracy: 0.9443 - val_loss: 1.9734 - val_accuracy: 0.5679\n",
      "Epoch 268/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1798 - accuracy: 0.9410 - val_loss: 1.8994 - val_accuracy: 0.5599\n",
      "Epoch 269/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1742 - accuracy: 0.9439 - val_loss: 1.9643 - val_accuracy: 0.5684\n",
      "Epoch 270/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1744 - accuracy: 0.9430 - val_loss: 2.0028 - val_accuracy: 0.5676\n",
      "Epoch 271/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1732 - accuracy: 0.9436 - val_loss: 2.0897 - val_accuracy: 0.5630\n",
      "Epoch 272/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1710 - accuracy: 0.9442 - val_loss: 2.0163 - val_accuracy: 0.5698\n",
      "Epoch 273/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1707 - accuracy: 0.9446 - val_loss: 2.0095 - val_accuracy: 0.5686\n",
      "Epoch 274/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1855 - accuracy: 0.9417 - val_loss: 2.0433 - val_accuracy: 0.5698\n",
      "Epoch 275/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1743 - accuracy: 0.9441 - val_loss: 2.0051 - val_accuracy: 0.5627\n",
      "Epoch 276/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1748 - accuracy: 0.9422 - val_loss: 2.0155 - val_accuracy: 0.5715\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 16s 17ms/step - loss: 0.1720 - accuracy: 0.9440 - val_loss: 1.9943 - val_accuracy: 0.5692\n",
      "Epoch 278/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1733 - accuracy: 0.9426 - val_loss: 2.0104 - val_accuracy: 0.5650\n",
      "Epoch 279/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1703 - accuracy: 0.9453 - val_loss: 2.0524 - val_accuracy: 0.5654\n",
      "Epoch 280/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1686 - accuracy: 0.9446 - val_loss: 2.0026 - val_accuracy: 0.5675\n",
      "Epoch 281/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1749 - accuracy: 0.9440 - val_loss: 1.9985 - val_accuracy: 0.5652\n",
      "Epoch 282/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1716 - accuracy: 0.9439 - val_loss: 1.9627 - val_accuracy: 0.5665\n",
      "Epoch 283/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1767 - accuracy: 0.9428 - val_loss: 1.9739 - val_accuracy: 0.5674\n",
      "Epoch 284/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1788 - accuracy: 0.9420 - val_loss: 2.0797 - val_accuracy: 0.5671\n",
      "Epoch 285/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1651 - accuracy: 0.9462 - val_loss: 2.1426 - val_accuracy: 0.5669\n",
      "Epoch 286/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1604 - accuracy: 0.9463 - val_loss: 2.0619 - val_accuracy: 0.5667\n",
      "Epoch 287/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1638 - accuracy: 0.9455 - val_loss: 2.0257 - val_accuracy: 0.5606\n",
      "Epoch 288/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1747 - accuracy: 0.9434 - val_loss: 1.9844 - val_accuracy: 0.5671\n",
      "Epoch 289/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1729 - accuracy: 0.9433 - val_loss: 2.0985 - val_accuracy: 0.5674\n",
      "Epoch 290/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1748 - accuracy: 0.9435 - val_loss: 2.0690 - val_accuracy: 0.5699\n",
      "Epoch 291/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1642 - accuracy: 0.9464 - val_loss: 2.1637 - val_accuracy: 0.5645\n",
      "Epoch 292/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1651 - accuracy: 0.9462 - val_loss: 2.0268 - val_accuracy: 0.5623\n",
      "Epoch 293/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1703 - accuracy: 0.9446 - val_loss: 2.0901 - val_accuracy: 0.5662\n",
      "Epoch 294/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1657 - accuracy: 0.9454 - val_loss: 1.9959 - val_accuracy: 0.5637\n",
      "Epoch 295/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1703 - accuracy: 0.9465 - val_loss: 1.9543 - val_accuracy: 0.5689\n",
      "Epoch 296/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1669 - accuracy: 0.9453 - val_loss: 2.0877 - val_accuracy: 0.5645\n",
      "Epoch 297/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1630 - accuracy: 0.9468 - val_loss: 2.0287 - val_accuracy: 0.5628\n",
      "Epoch 298/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1729 - accuracy: 0.9442 - val_loss: 2.0558 - val_accuracy: 0.5661\n",
      "Epoch 299/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1688 - accuracy: 0.9463 - val_loss: 2.0675 - val_accuracy: 0.5641\n",
      "Epoch 300/300\n",
      "901/901 [==============================] - 15s 17ms/step - loss: 0.1692 - accuracy: 0.9449 - val_loss: 2.1523 - val_accuracy: 0.5702\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    history = model.fit(X, y, \n",
    "                        epochs=300, \n",
    "                        batch_size = 32, \n",
    "                        shuffle=True, \n",
    "                        validation_data=(validation_X, validation_y),\n",
    "                        callbacks = [thresholdcallback])\n",
    "    \n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_classifier.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_classifier.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
